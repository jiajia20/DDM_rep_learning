# DDM_rep_learning
Learning reputation to increase cooperation among IBL cognitive agents

## Ways of manipulating the agent’s learning

In IBL model the agents can learn through the three following variable

| Variable\Name			| Simple_rep    | Simple_rep    |
| ----------- 			| -----------   |  -----------   | 
| Instance				| [button,rep]  |
| payoff				| self pay-off  |
| utility				| self pay-off  |
| paritial matching	    | No            |


Those can be measured in the following variable

| Name					| Description |
| ----------- 			| ----------- |
| choice of button	    |		 Text  |
| blending value		|		 Text  |
| activation of instance|		 Text  |



## table of content

### 0 - DDM OG

contain the original file coded by Coty and Don. 
This include paired game with 
1)no information 
2)alter identity info 
3)partial paring 
4)included the payoff of alter into ego’s utility function
It also include new field that 
1) change the agent from 6 to 12
2) visualization that examies the ratio of choice overtime from a CSV file

### 1 - Reputation_learning_modifed_from _OG
This is the first attempt to include reputation learning in the original binary choice game. This version the repuation information is ot updating right after adding alhazen. 

### 2 - Reputation_learning_in_loop
- fix the reputation updating by removing alhazen and write the simulation only in loops
- specified four different loops and the related vaiables 
  

## 